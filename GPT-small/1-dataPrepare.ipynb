{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca295bb-ed53-4d1f-9aea-f69c7011c5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp312-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (69.5.1)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.7.0-cp312-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sympy, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "Successfully installed sympy-1.14.0 torch-2.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "256c028f-1ce9-400d-b3a4-e75b327037b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.exists(\"test.txt\"):\n",
    "    url = (\"https://raw.githubusercontent.com/Mengjie-Guo/LLM/master/GPT-small/test.txt\")\n",
    "    file_path = \"test.txt\"\n",
    "    urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e9c958-8a92-4534-b55b-10fe75838bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always though\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05566927-905f-4dad-a8db-1edc35197aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good', ' ', '', ' ', 'night', '.', '', ' ', 'Are', ' ', 'you', ' ', '', '--', 'ok', '?', '']\n",
      "['Good', 'night', '.', 'Are', 'you', '--', 'ok', '?']\n"
     ]
    }
   ],
   "source": [
    "text = \"Good  night. Are you --ok?\"\n",
    "\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "print(result)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6d251e7-ee96-4dfd-9805-6cfbd3006b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pretext = re.split(r'([,.;?!\"_()\\']|\\s|--)', raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17226e3b-9e6f-468c-9300-4ce3a385e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretext = [item.strip() for item in pretext if\n",
    "item.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6259f76-ab54-49eb-b786-fcf3d0853e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4670\n",
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap']\n"
     ]
    }
   ],
   "source": [
    "print(len(pretext))\n",
    "print(pretext[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38d75886-a9b8-4675-b922-b7e102b75878",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words=sorted(set(pretext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a5964f0-aec1-4fbf-8279-c5aad1564a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146\n"
     ]
    }
   ],
   "source": [
    "word_cnt=len(all_words)\n",
    "print(word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "331bfec4-4908-4954-a802-f18824c600d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', \"'\", '(', ')', ',', '--', '.', ':', ';']\n"
     ]
    }
   ],
   "source": [
    "print(all_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9c3b52f-2c38-455b-bbd3-86f86e3e1e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! : 0\n",
      "\" : 1\n",
      "' : 2\n",
      "( : 3\n",
      ") : 4\n",
      ", : 5\n",
      "-- : 6\n",
      ". : 7\n",
      ": : 8\n",
      "; : 9\n",
      "? : 10\n"
     ]
    }
   ],
   "source": [
    "vocab = {token:index for index,token in enumerate(all_words)}\n",
    "i=0\n",
    "for key,val in vocab.items():\n",
    "    i += 1\n",
    "    print(key,\":\",val)\n",
    "    if i > 10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "46d4386e-0cec-457a-b6bf-3321957482e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_int = vocab\n",
    "        self.int_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        pretext = re.split(r'([,.;?!\"_()\\']|\\s|--)', text)\n",
    "        pretext = [item.strip() for item in pretext if item.strip()]\n",
    "        indexs = [self.str_int[s] for s in pretext]\n",
    "        return indexs\n",
    "\n",
    "    def decode(self, indexs):\n",
    "        text = \" \".join(self.int_str[i] for i in indexs)\n",
    "        # Replace spaces before the below punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1da4b6ba-e87c-4d1f-a0b0-6b8657de24c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109, 2, 830, 573, 1002, 292, 5, 67, 7, 38, 7, 1, 53, 2, 830, 1142, 10]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TokenizerV1(vocab)\n",
    "text = \"\"\"We're in the corner, Mr. Gisburn. \"How're you?\"\"\"\n",
    "indexs = tokenizer.encode(text)\n",
    "print(indexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "910a3e6a-8e2d-419d-ab3b-2d6affede763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We\\' re in the corner, Mr. Gisburn.\" How\\' re you?'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(indexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f03100d1-bb43-411a-98a9-f0639d85c479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We\\' re in the corner, Mr. Gisburn.\" How\\' re you?'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5f633025-4097-4c31-b466-cc46a887b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add special tokens unknown:\"<|unk|>\" and the end of a text \"<|endoftext|>\"\n",
    "all_words.extend([\"<|endoftext|>\", \"<|unk|>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b383c2cd-fb8f-4255-b9b0-f84c69e6dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {s:i for i,s in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6d218965-47b5-4035-9f8b-8f9526947141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148 1148\n"
     ]
    }
   ],
   "source": [
    "print(len(all_words), len(vocab.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "01e19b58-ab51-4bb6-8829-0f3f53db00be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1143)\n",
      "('your', 1144)\n",
      "('yourself', 1145)\n",
      "('<|endoftext|>', 1146)\n",
      "('<|unk|>', 1147)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "838bb09f-01c1-4b61-88f6-85059311eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_int = vocab\n",
    "        self.int_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        pretext = re.split(r'([,.;?!\"_()\\']|\\s|--)', text)\n",
    "        #print(pretext)\n",
    "        pretext = [item.strip() for item in pretext if item.strip()]\n",
    "        pretext = [\n",
    "            item if item in self.str_int\n",
    "            else \"<|unk|>\" for item in pretext\n",
    "        ]\n",
    "        indexs = [self.str_int[s] for s in pretext]\n",
    "        return indexs\n",
    "\n",
    "    def decode(self, indexs):\n",
    "        text = \" \".join(self.int_str[i] for i in indexs)\n",
    "        # Replace spaces before the below punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "73df6afb-15b3-4a7d-9f6d-509d79574a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TokenizerV2(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9bed77e5-43cd-48ac-84e6-a0a1e230124c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, Mr. Gisburn. <|endoftext|> Are you from?\n",
      "[1147, 5, 67, 7, 38, 7, 1146, 15, 1142, 480, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|unk|>, Mr. Gisburn. <|endoftext|> Are you from?'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"Hi, Mr. Gisburn.\"\n",
    "text2 = \"Are you from?\"\n",
    "text = \" <|endoftext|> \".join((text1,text2)) #space needed to avoid \n",
    "print(text)\n",
    "indexs = tokenizer.encode(text)\n",
    "print(indexs)\n",
    "tokenizer.decode(indexs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "62ba6ef5-7267-4624-8d23-1a5d0f6e451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entext=tokenizer.encode(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "85f1bfb7-ffc1-4a63-a3d3-705ad7d2ab10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54, 45, 151, 1017, 58, 38, 829, 117, 258]\n",
      "4670\n"
     ]
    }
   ],
   "source": [
    "print(entext[:9])\n",
    "print(len(entext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "40a378ff-5b47-4742-8eb8-7da5968f476e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54, 45]\n",
      "[45, 151]\n",
      "[151, 1017]\n",
      "[1017, 58]\n",
      "[58, 38]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5, 1):\n",
    "    print(entext[i:i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ddfc69c2-b302-4c33-9582-ffc7af9af69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 I -> HAD\n",
      "3 I HAD always -> thought\n",
      "5 I HAD always thought Jack -> Gisburn\n"
     ]
    }
   ],
   "source": [
    "#next-word prediction\n",
    "ensample = entext[:50]\n",
    "context_size = 5\n",
    "for i in range(1, context_size+1, 2):\n",
    "    context = ensample[:i]\n",
    "    predicted = ensample[i]\n",
    "    print(i, tokenizer.decode(context), \"->\", tokenizer.decode([predicted]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "41303de1-8ac2-4888-9836-ddda1566d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "da0f19ab-5a1e-4cc4-8c12-2b759b0f5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, txt, tokenizer, maxlen, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        \n",
    "        tokenids = tokenizer.encode(txt, allowed_special = {\"<|endoftext|>\"})\n",
    "        print(tokenids[:50])\n",
    "        assert len(tokenids) > maxlen, \"Input token length can't less than maxlen\"\n",
    "\n",
    "        #sliding window to chunk text\n",
    "        for i in range(0, len(tokenids) - maxlen, stride):\n",
    "            input = tokenids[i:i+maxlen]\n",
    "            target = tokenids[i+1:i+1+maxlen]\n",
    "            self.input_ids.append(input)\n",
    "            self.target_ids.append(target)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fdc3003c-d4fb-4ea8-96a2-4e82cd9e4951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4b4fbccf-03f9-4d69-a3b7-f73952bb7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def create_dataloader(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDataset(txt, tokenizer, max_length, stride)\n",
    "    print(dataset.__len__())\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=drop_last)\n",
    "\n",
    "    return dataloader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "28ad70b9-a512-4f36-9d84-e10a4ce632ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138, 257, 7026, 15632, 438, 2016, 257, 922, 5891, 1576, 438, 568, 340, 373, 645, 1049, 5975, 284, 502, 284, 3285, 326, 11, 287, 262, 6001, 286, 465, 13476, 11, 339, 550, 5710, 465, 12036, 11, 6405, 257, 5527, 27075, 11]\n",
      "1286\n",
      "Inputs:\n",
      " [tensor([   40,  1807, 10899, 15632,   922,   568,  1049,   284]), tensor([ 367, 3619, 2138,  438, 5891,  340, 5975, 3285]), tensor([2885,  402,  257, 2016, 1576,  373,  284,  326]), tensor([1464,  271, 7026,  257,  438,  645,  502,   11])]\n",
      "\n",
      "Targets:\n",
      " [tensor([ 367, 3619, 2138,  438, 5891,  340, 5975, 3285]), tensor([2885,  402,  257, 2016, 1576,  373,  284,  326]), tensor([1464,  271, 7026,  257,  438,  645,  502,   11]), tensor([ 1807, 10899, 15632,   922,   568,  1049,   284,   287])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False, drop_last=True, num_workers=0)\n",
    "\n",
    "dataiter=iter(dataloader)\n",
    "inputs, targets = next(dataiter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7fb8f3f8-69fb-440a-9af4-7c1226ed085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputids = [4,6,3,1,5]\n",
    "# small vocab contains only 7 words\n",
    "vocabsize=7\n",
    "outputdim=4\n",
    "torch.manual_seed(123)\n",
    "embeddinglayer=torch.nn.Embedding(vocabsize, outputdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6053c4aa-4d3a-4cd4-be8c-43bc95f43ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880],\n",
      "        [ 0.3486,  0.6603, -0.2196, -0.3792],\n",
      "        [ 0.7671, -1.1925,  0.6984, -1.4097],\n",
      "        [ 1.8960, -0.1750,  1.3689, -1.6033],\n",
      "        [-1.3250,  0.1784, -2.1338,  1.0524],\n",
      "        [ 0.9985,  0.2212,  1.8319, -0.3378],\n",
      "        [ 0.8805,  1.5542,  0.6266, -0.1755]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embeddinglayer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a55fad40-586f-41f0-bcb2-eef06be6971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.9985,  0.2212,  1.8319, -0.3378], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embeddinglayer(torch.tensor(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d7bd5611-4d70-4b63-9811-5ca13dff7b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3250,  0.1784, -2.1338,  1.0524],\n",
      "        [ 0.8805,  1.5542,  0.6266, -0.1755],\n",
      "        [ 1.8960, -0.1750,  1.3689, -1.6033],\n",
      "        [ 0.3486,  0.6603, -0.2196, -0.3792],\n",
      "        [ 0.9985,  0.2212,  1.8319, -0.3378]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embeddinglayer(torch.tensor(inputids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5c065989-378c-485c-bd04-c7fb9f72fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149fae94-7502-4201-bf7a-77067674fa3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
