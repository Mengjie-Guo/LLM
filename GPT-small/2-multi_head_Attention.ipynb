{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUUDKnRDwuGy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1]\n",
        "attnscores = torch.empty(inputs.shape[0])\n",
        "for i,x_i in enumerate(inputs):\n",
        "  attnscores[i] = torch.dot(query, x_i)\n",
        "\n",
        "print(attnscores)"
      ],
      "metadata": {
        "id": "4R7SvwXyysCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e20abd-3235-4366-f7c6-390bf25dfcd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = 0\n",
        "for i,item in enumerate(inputs[0]):\n",
        "  res += inputs[0][i] * query[i]\n",
        "  print(inputs[0][i], \"*\", query[i])\n",
        "print(res)\n",
        "print(torch.dot(inputs[0], query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk_LzfwxXfV0",
        "outputId": "c2b23b5f-47fa-403f-da25-825987e09616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.4300) * tensor(0.5500)\n",
            "tensor(0.1500) * tensor(0.8700)\n",
            "tensor(0.8900) * tensor(0.6600)\n",
            "tensor(0.9544)\n",
            "tensor(0.9544)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize\n",
        "attweights = attnscores / attnscores.sum()\n",
        "print(attweights)\n",
        "print(attweights.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f79f_dXkX_5P",
        "outputId": "6f352ffb-0423-4630-df46-8509a76dd4f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
            "tensor(1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_n(x):\n",
        "  return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
        "\n",
        "attweightsn = softmax_n(attnscores)\n",
        "print(attweightsn)\n",
        "print(attweightsn.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPfEHKSHz7MV",
        "outputId": "9a55b6d6-563e-4d53-bfb8-133527dc6f47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# softmax for normalization, handle extreme values and good gradient\n",
        "atteweights2 = torch.softmax(attnscores, dim=0)\n",
        "print(atteweights2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQmTeKPrd54i",
        "outputId": "658bbfdc-fc90-40ae-94aa-065b456a4d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1]\n",
        "contextvec2 = torch.zeros(query.shape)\n",
        "print(contextvec2)\n",
        "for i, xi in enumerate(inputs):\n",
        "  contextvec2 += atteweights2[i]*xi\n",
        "  print(atteweights2[i], \"*\", xi)\n",
        "\n",
        "print(contextvec2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSXGofsR6pKG",
        "outputId": "0230ebca-3b3a-4b7e-d218-f5a52b901138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0.])\n",
            "tensor(0.1385) * tensor([0.4300, 0.1500, 0.8900])\n",
            "tensor(0.2379) * tensor([0.5500, 0.8700, 0.6600])\n",
            "tensor(0.2333) * tensor([0.5700, 0.8500, 0.6400])\n",
            "tensor(0.1240) * tensor([0.2200, 0.5800, 0.3300])\n",
            "tensor(0.1082) * tensor([0.7700, 0.2500, 0.1000])\n",
            "tensor(0.1581) * tensor([0.0500, 0.8000, 0.5500])\n",
            "tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attenScores = torch.empty(6,6)\n",
        "for i,xi in enumerate(inputs):\n",
        "  for j,xj in enumerate(inputs):\n",
        "    attenScores[i,j] = torch.dot(xi, xj)\n",
        "    print(xi, \"*\", xj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7m6SSN3BEAj",
        "outputId": "c4988f61-9856-4432-f438-b64a35298593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4300, 0.1500, 0.8900]) * tensor([0.4300, 0.1500, 0.8900])\n",
            "tensor([0.4300, 0.1500, 0.8900]) * tensor([0.5500, 0.8700, 0.6600])\n",
            "tensor([0.4300, 0.1500, 0.8900]) * tensor([0.5700, 0.8500, 0.6400])\n",
            "tensor([0.4300, 0.1500, 0.8900]) * tensor([0.2200, 0.5800, 0.3300])\n",
            "tensor([0.4300, 0.1500, 0.8900]) * tensor([0.7700, 0.2500, 0.1000])\n",
            "tensor([0.4300, 0.1500, 0.8900]) * tensor([0.0500, 0.8000, 0.5500])\n",
            "tensor([0.5500, 0.8700, 0.6600]) * tensor([0.4300, 0.1500, 0.8900])\n",
            "tensor([0.5500, 0.8700, 0.6600]) * tensor([0.5500, 0.8700, 0.6600])\n",
            "tensor([0.5500, 0.8700, 0.6600]) * tensor([0.5700, 0.8500, 0.6400])\n",
            "tensor([0.5500, 0.8700, 0.6600]) * tensor([0.2200, 0.5800, 0.3300])\n",
            "tensor([0.5500, 0.8700, 0.6600]) * tensor([0.7700, 0.2500, 0.1000])\n",
            "tensor([0.5500, 0.8700, 0.6600]) * tensor([0.0500, 0.8000, 0.5500])\n",
            "tensor([0.5700, 0.8500, 0.6400]) * tensor([0.4300, 0.1500, 0.8900])\n",
            "tensor([0.5700, 0.8500, 0.6400]) * tensor([0.5500, 0.8700, 0.6600])\n",
            "tensor([0.5700, 0.8500, 0.6400]) * tensor([0.5700, 0.8500, 0.6400])\n",
            "tensor([0.5700, 0.8500, 0.6400]) * tensor([0.2200, 0.5800, 0.3300])\n",
            "tensor([0.5700, 0.8500, 0.6400]) * tensor([0.7700, 0.2500, 0.1000])\n",
            "tensor([0.5700, 0.8500, 0.6400]) * tensor([0.0500, 0.8000, 0.5500])\n",
            "tensor([0.2200, 0.5800, 0.3300]) * tensor([0.4300, 0.1500, 0.8900])\n",
            "tensor([0.2200, 0.5800, 0.3300]) * tensor([0.5500, 0.8700, 0.6600])\n",
            "tensor([0.2200, 0.5800, 0.3300]) * tensor([0.5700, 0.8500, 0.6400])\n",
            "tensor([0.2200, 0.5800, 0.3300]) * tensor([0.2200, 0.5800, 0.3300])\n",
            "tensor([0.2200, 0.5800, 0.3300]) * tensor([0.7700, 0.2500, 0.1000])\n",
            "tensor([0.2200, 0.5800, 0.3300]) * tensor([0.0500, 0.8000, 0.5500])\n",
            "tensor([0.7700, 0.2500, 0.1000]) * tensor([0.4300, 0.1500, 0.8900])\n",
            "tensor([0.7700, 0.2500, 0.1000]) * tensor([0.5500, 0.8700, 0.6600])\n",
            "tensor([0.7700, 0.2500, 0.1000]) * tensor([0.5700, 0.8500, 0.6400])\n",
            "tensor([0.7700, 0.2500, 0.1000]) * tensor([0.2200, 0.5800, 0.3300])\n",
            "tensor([0.7700, 0.2500, 0.1000]) * tensor([0.7700, 0.2500, 0.1000])\n",
            "tensor([0.7700, 0.2500, 0.1000]) * tensor([0.0500, 0.8000, 0.5500])\n",
            "tensor([0.0500, 0.8000, 0.5500]) * tensor([0.4300, 0.1500, 0.8900])\n",
            "tensor([0.0500, 0.8000, 0.5500]) * tensor([0.5500, 0.8700, 0.6600])\n",
            "tensor([0.0500, 0.8000, 0.5500]) * tensor([0.5700, 0.8500, 0.6400])\n",
            "tensor([0.0500, 0.8000, 0.5500]) * tensor([0.2200, 0.5800, 0.3300])\n",
            "tensor([0.0500, 0.8000, 0.5500]) * tensor([0.7700, 0.2500, 0.1000])\n",
            "tensor([0.0500, 0.8000, 0.5500]) * tensor([0.0500, 0.8000, 0.5500])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(attenScores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWaNQlY3DBhG",
        "outputId": "fba00270-d12d-4f78-978d-dc460be57182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1,2], [3,4], [0, 3]])\n",
        "y = torch.tensor([[1,1,1], [0,0,1]])\n",
        "print(torch.sum(x, dim=-1)) #row sum\n",
        "print(torch.sum(x, dim=1))\n",
        "print(torch.sum(x, dim=0))\n",
        "print(x @ y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzcHbBbFDzaD",
        "outputId": "4a1a9754-63a7-4176-daef-673142e3b8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 7, 3])\n",
            "tensor([3, 7, 3])\n",
            "tensor([4, 9])\n",
            "tensor([[1, 1, 3],\n",
            "        [3, 3, 7],\n",
            "        [0, 0, 3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attenWeights = torch.softmax(attenScores, dim=-1)\n",
        "print(attenWeights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvKKmaXNDP2Z",
        "outputId": "6f470d1d-be46-41de-d52c-e144560f9f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
            "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
            "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
            "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
            "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
            "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(attenWeights[1].sum(dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6DuIvzhEdFu",
        "outputId": "0157731e-8aad-4a98-8b38-c246f4b7fb99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contextVectors = attenWeights @ inputs\n",
        "print(contextVectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKms6GB_Erfl",
        "outputId": "e76c9d9a-9f8e-41dc-d2cf-172e6ad377b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contextVectors = torch.matmul(attenWeights, inputs)\n",
        "print(contextVectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjwmuERGFjNV",
        "outputId": "2638ff02-8648-440d-dad0-f0860e21f32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = inputs[1]\n",
        "din = inputs.shape[1]\n",
        "dout = 2\n",
        "\n",
        "torch.manual_seed(1)\n",
        "queryW = torch.nn.Parameter(torch.rand(din, dout), requires_grad=False)\n",
        "keyW = torch.nn.Parameter(torch.rand(din, dout), requires_grad=False)\n",
        "valueW = torch.nn.Parameter(torch.rand(din, dout), requires_grad=False)"
      ],
      "metadata": {
        "id": "17CJRhogG30f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q2 = x2 @ queryW\n",
        "k2 = x2 @ keyW\n",
        "v2 = x2 @ valueW\n",
        "print(q2)\n",
        "print(k2)\n",
        "print(v2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grp-1hOVka8H",
        "outputId": "cb69a72d-b8be-4e25-b99d-3036aaa8e1f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7867, 1.3207])\n",
            "tensor([1.1354, 1.1429])\n",
            "tensor([1.1566, 0.8924])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = inputs @ keyW\n",
        "values = inputs @ valueW\n",
        "print(keys)\n",
        "print(values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqnKDGUmkodO",
        "outputId": "985e5570-956c-49c6-ac9c-828dc3e1e7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8246, 0.8571],\n",
            "        [1.1354, 1.1429],\n",
            "        [1.1192, 1.1387],\n",
            "        [0.6284, 0.5936],\n",
            "        [0.5120, 0.7430],\n",
            "        [0.8267, 0.6773]])\n",
            "tensor([[0.8726, 0.6427],\n",
            "        [1.1566, 0.8924],\n",
            "        [1.1495, 0.8794],\n",
            "        [0.6079, 0.4954],\n",
            "        [0.6987, 0.3985],\n",
            "        [0.7198, 0.6531]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys2 = keys[1]\n",
        "print(keys2)\n",
        "attscore22 = q2.dot(keys2)\n",
        "print(attscore22)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Mdmscnjkz39",
        "outputId": "b6cb518e-e39d-45bd-b9d2-1ce59214561f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.1354, 1.1429])\n",
            "tensor(2.4027)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all att scores for the query q2\n",
        "attScores2 = q2 @ keys.T\n",
        "print(attScores2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXn31OYMlvnB",
        "outputId": "477c7764-3d1f-4e07-9d70-8b70fd5d1cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.7808, 2.4027, 2.3844, 1.2784, 1.3841, 1.5449])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Scaled-dot product attention**:\n",
        " The reason for the normalization by the embedding dimension size is to\n",
        " improve the training performance by avoiding small gradients. For instance,\n",
        " when scaling up the embedding dimension, which is typically greater than\n",
        " thousand for GPT-like LLMs, large dot products can result in very small\n",
        " gradients during backpropagation due to the softmax function applied to\n",
        " them. As dot products increase, the softmax function behaves more like a\n",
        " step function, resulting in gradients nearing zero. These small gradients can\n",
        " drastically slow down learning or cause training to stagnate."
      ],
      "metadata": {
        "id": "voeeM4FEnJ5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dk = keys.shape[1]\n",
        "attenWeights2 = torch.softmax(attScores2 / torch.sqrt(torch.tensor(dk)), dim=-1)\n",
        "attenWeights2_ = torch.softmax(attScores2 / dk**0.5, dim=-1)\n",
        "print(attenWeights2)\n",
        "print(attenWeights2_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtxdNzXrmXUf",
        "outputId": "58283c8e-e13f-425a-d192-ec59517cf042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1566, 0.2430, 0.2399, 0.1097, 0.1183, 0.1325])\n",
            "tensor([0.1566, 0.2430, 0.2399, 0.1097, 0.1183, 0.1325])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#context vector for q2\n",
        "contextVectors2 = attenWeights2 @ values\n",
        "print(contextVectors2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaC_U7Ntn5CF",
        "outputId": "90e7a4cc-e7b8-4f4e-c73e-fb72d88c214b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9382, 0.7165])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self Attention"
      ],
      "metadata": {
        "id": "hwpvMLUeByhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")"
      ],
      "metadata": {
        "id": "60jNUBaBCwbK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self, din, dout):\n",
        "    super().__init__()\n",
        "    self.queryW = nn.Parameter(torch.rand(din, dout)) #, requires_grad=True\n",
        "    self.keyW = nn.Parameter(torch.rand(din, dout))\n",
        "    self.valueW = nn.Parameter(torch.rand(din, dout))\n",
        "\n",
        "  def forward(self, x):\n",
        "    keys = x @ self.keyW\n",
        "    values = x @ self.valueW\n",
        "    queries = x @ self.queryW\n",
        "    attScores = queries @ keys.T\n",
        "    attenWeights = torch.softmax(attScores / keys.shape[1]**0.5, dim = -1) # row ops\n",
        "    contextVectors = attenWeights @ values\n",
        "    return contextVectors\n",
        "\n",
        "torch.manual_seed(1)\n",
        "selfatt = SelfAttention(3, 2)\n",
        "print(selfatt(inputs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrPHdq8P6gys",
        "outputId": "f615ea05-28a4-4eec-c488-4d1de2c59a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9128, 0.6959],\n",
            "        [0.9382, 0.7165],\n",
            "        [0.9376, 0.7161],\n",
            "        [0.9062, 0.6910],\n",
            "        [0.9063, 0.6924],\n",
            "        [0.9149, 0.6973]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "a = nn.Linear(3,2)(inputs)\n",
        "print(a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69_WWDkf5-5k",
        "outputId": "8f5c36a6-307b-4c2e-d00b-bdc90c3598a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1324, -0.3585],\n",
            "        [ 0.1070, -0.4127],\n",
            "        [ 0.1178, -0.4128],\n",
            "        [-0.0407, -0.1874],\n",
            "        [ 0.2270, -0.2899],\n",
            "        [-0.1343, -0.2042]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttentionV2(nn.Module):\n",
        "  def __init__(self, din, dout, bias=False):\n",
        "    super().__init__()\n",
        "    self.queryW = nn.Linear(din, dout, bias)\n",
        "    self.keyW = nn.Linear(din, dout, bias)\n",
        "    self.valueW = nn.Linear(din, dout, bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    keys = self.keyW(x)\n",
        "    values = self.valueW(x)\n",
        "    queries = self.queryW(x)\n",
        "    attScores = queries @ keys.T\n",
        "    attenWeights = torch.softmax(attScores / keys.shape[-1]**0.5, dim=-1)\n",
        "    contextVectors = attenWeights @ values\n",
        "    return contextVectors\n",
        "\n",
        "torch.manual_seed(1)\n",
        "selfatt = SelfAttentionV2(3, 2)\n",
        "print(selfatt(inputs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdHaBh3l07jM",
        "outputId": "b18b8e09-5299-4ed2-c2a2-a99821ddc2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0636,  0.0255],\n",
            "        [-0.0612,  0.0248],\n",
            "        [-0.0613,  0.0248],\n",
            "        [-0.0611,  0.0247],\n",
            "        [-0.0639,  0.0256],\n",
            "        [-0.0599,  0.0244]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Causal Attention Mask\n",
        "only consider the previous and current inputs in a sequence"
      ],
      "metadata": {
        "id": "Ld-uxzkvBzzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = selfatt.queryW(inputs)\n",
        "keys = selfatt.keyW(inputs)\n",
        "attScores = queries @ keys.T\n",
        "print(attScores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V3dLv7N7H0g",
        "outputId": "e07423d8-fc8a-48d5-ae52-f3eb66bbffb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0059,  0.0385,  0.0368,  0.0281, -0.0039,  0.0454],\n",
            "        [-0.0103, -0.0435, -0.0417, -0.0308,  0.0024, -0.0494],\n",
            "        [-0.0093, -0.0391, -0.0375, -0.0277,  0.0022, -0.0445],\n",
            "        [-0.0104, -0.0459, -0.0440, -0.0326,  0.0028, -0.0524],\n",
            "        [ 0.0120,  0.0503,  0.0482,  0.0356, -0.0028,  0.0572],\n",
            "        [-0.0205, -0.0885, -0.0848, -0.0628,  0.0052, -0.1008]],\n",
            "       grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attWeights = torch.softmax(attScores / keys.shape[-1]**0.5, dim=-1)\n",
        "print(attWeights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0j9Hp2OA3Lz",
        "outputId": "8ceedae1-4120-4821-dded-8046d76c54aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1644, 0.1682, 0.1680, 0.1670, 0.1633, 0.1691],\n",
            "        [0.1689, 0.1649, 0.1652, 0.1664, 0.1704, 0.1642],\n",
            "        [0.1686, 0.1651, 0.1653, 0.1665, 0.1700, 0.1645],\n",
            "        [0.1690, 0.1648, 0.1651, 0.1664, 0.1706, 0.1641],\n",
            "        [0.1641, 0.1686, 0.1684, 0.1669, 0.1624, 0.1695],\n",
            "        [0.1712, 0.1631, 0.1636, 0.1661, 0.1743, 0.1617]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contsize = attWeights.shape[0]\n",
        "mask1 = torch.tril(torch.ones(contsize, contsize))\n",
        "print(mask1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QhB5qzTBav9",
        "outputId": "889b9055-9538-406b-ac4b-77d1fc89d8b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maskedWeights1 = mask1 * attWeights\n",
        "print(maskedWeights1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90SfT5v7EkD6",
        "outputId": "c1008fb6-211a-45a4-c418-35880979a59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1644, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1689, 0.1649, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1686, 0.1651, 0.1653, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1690, 0.1648, 0.1651, 0.1664, 0.0000, 0.0000],\n",
            "        [0.1641, 0.1686, 0.1684, 0.1669, 0.1624, 0.0000],\n",
            "        [0.1712, 0.1631, 0.1636, 0.1661, 0.1743, 0.1617]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# norm above maskedWeights1\n",
        "rowSum = maskedWeights1.sum(dim=-1, keepdim=True)\n",
        "normWeights1 = maskedWeights1 / rowSum\n",
        "print(normWeights1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sabub_OdEvio",
        "outputId": "25f0c3ad-38ca-487d-90fd-e01c08d19341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5059, 0.4941, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3379, 0.3309, 0.3312, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2541, 0.2478, 0.2481, 0.2501, 0.0000, 0.0000],\n",
            "        [0.1976, 0.2031, 0.2028, 0.2010, 0.1956, 0.0000],\n",
            "        [0.1712, 0.1631, 0.1636, 0.1661, 0.1743, 0.1617]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask2 = torch.triu(torch.ones(contsize, contsize), diagonal=1)\n",
        "print(mask2)\n",
        "print(mask2.bool())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WzcSLd_FTeN",
        "outputId": "1adf1ade-8249-4331-dc4a-d351ad70ffb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 1., 1., 1., 1., 1.],\n",
            "        [0., 0., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0.]])\n",
            "tensor([[False,  True,  True,  True,  True,  True],\n",
            "        [False, False,  True,  True,  True,  True],\n",
            "        [False, False, False,  True,  True,  True],\n",
            "        [False, False, False, False,  True,  True],\n",
            "        [False, False, False, False, False,  True],\n",
            "        [False, False, False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked2 = attScores.masked_fill(mask2.bool(), float('-inf'))\n",
        "print(masked2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBEF7gRJFm5i",
        "outputId": "2f045e45-531d-474f-848f-f7909b370edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0059,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
            "        [-0.0103, -0.0435,    -inf,    -inf,    -inf,    -inf],\n",
            "        [-0.0093, -0.0391, -0.0375,    -inf,    -inf,    -inf],\n",
            "        [-0.0104, -0.0459, -0.0440, -0.0326,    -inf,    -inf],\n",
            "        [ 0.0120,  0.0503,  0.0482,  0.0356, -0.0028,    -inf],\n",
            "        [-0.0205, -0.0885, -0.0848, -0.0628,  0.0052, -0.1008]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attWeights2 = torch.softmax(masked2 / keys.shape[-1]**0.5, dim=-1)\n",
        "print(attWeights2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyny8WbdFzh-",
        "outputId": "2581c0d4-4b0e-4f11-8406-259a57c762b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5059, 0.4941, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3379, 0.3309, 0.3312, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2541, 0.2478, 0.2481, 0.2501, 0.0000, 0.0000],\n",
            "        [0.1976, 0.2031, 0.2028, 0.2010, 0.1956, 0.0000],\n",
            "        [0.1712, 0.1631, 0.1636, 0.1661, 0.1743, 0.1617]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add dropout: reduce overfitting during training"
      ],
      "metadata": {
        "id": "PKmv0qDWGbvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "dropout = torch.nn.Dropout(0.5)\n",
        "print(dropout(attWeights2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjHHxmESGfjv",
        "outputId": "da4c2a94-6b02-41c6-a1d2-beec66207091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.9883, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.6758, 0.0000, 0.6625, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5081, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3953, 0.0000, 0.4055, 0.4019, 0.0000, 0.0000],\n",
            "        [0.3423, 0.0000, 0.0000, 0.0000, 0.3486, 0.0000]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# support to handle batch\n",
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "print(batch)\n",
        "print(batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a90QnYKIXtM",
        "outputId": "41a26ba5-859e-463e-da4c-5c500533b264"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.4300, 0.1500, 0.8900],\n",
            "         [0.5500, 0.8700, 0.6600],\n",
            "         [0.5700, 0.8500, 0.6400],\n",
            "         [0.2200, 0.5800, 0.3300],\n",
            "         [0.7700, 0.2500, 0.1000],\n",
            "         [0.0500, 0.8000, 0.5500]],\n",
            "\n",
            "        [[0.4300, 0.1500, 0.8900],\n",
            "         [0.5500, 0.8700, 0.6600],\n",
            "         [0.5700, 0.8500, 0.6400],\n",
            "         [0.2200, 0.5800, 0.3300],\n",
            "         [0.7700, 0.2500, 0.1000],\n",
            "         [0.0500, 0.8000, 0.5500]]])\n",
            "torch.Size([2, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = batch.transpose(0,1)\n",
        "print(test)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4MTNGbuMDoL",
        "outputId": "2614b58a-d996-48d4-967f-9f897886482a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.4300, 0.1500, 0.8900],\n",
            "         [0.4300, 0.1500, 0.8900]],\n",
            "\n",
            "        [[0.5500, 0.8700, 0.6600],\n",
            "         [0.5500, 0.8700, 0.6600]],\n",
            "\n",
            "        [[0.5700, 0.8500, 0.6400],\n",
            "         [0.5700, 0.8500, 0.6400]],\n",
            "\n",
            "        [[0.2200, 0.5800, 0.3300],\n",
            "         [0.2200, 0.5800, 0.3300]],\n",
            "\n",
            "        [[0.7700, 0.2500, 0.1000],\n",
            "         [0.7700, 0.2500, 0.1000]],\n",
            "\n",
            "        [[0.0500, 0.8000, 0.5500],\n",
            "         [0.0500, 0.8000, 0.5500]]])\n",
            "torch.Size([6, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class CausalAttention(nn.Module):\n",
        "  def __init__(self, din, dout, contextlen, dropout, bias=False):\n",
        "    super().__init__()\n",
        "    self.queryW = nn.Linear(din, dout, bias)\n",
        "    self.keyW = nn.Linear(din, dout, bias)\n",
        "    self.valueW = nn.Linear(din, dout, bias)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    # Registers the resulting mask as a buffer in the module,\n",
        "    # which means it will be part of the model's state but not updated during training.\n",
        "    self.register_buffer('mask', torch.triu(torch.ones(contextlen, contextlen), diagonal=1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    batchsize, numTokens, din = x.shape\n",
        "    keys = self.keyW(x)\n",
        "    values = self.valueW(x)\n",
        "    queries = self.queryW(x)\n",
        "\n",
        "    # print(\"queries\", queries)\n",
        "    attScores = queries @ keys.transpose(1, 2)\n",
        "    maskedScores = attScores.masked_fill(self.mask.bool()[:numTokens, :numTokens], float('-inf'))\n",
        "    #print(\"maskedScores\", maskedScores)\n",
        "    attWeights = torch.softmax(maskedScores / keys.shape[-1]**0.5, dim = -1)\n",
        "    #print(\"attWeights\", attWeights)\n",
        "    attWeights = self.dropout(attWeights)\n",
        "\n",
        "    contextVectors = attWeights @ values\n",
        "    return contextVectors\n",
        "\n",
        "torch.manual_seed(1)\n",
        "contextlen = batch.shape[1]\n",
        "causalatt = CausalAttention(3, 2, contextlen, 0.5)\n",
        "print(causalatt(batch))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 2*6*2 2*2*6=>2*6*6"
      ],
      "metadata": {
        "id": "hg07johRJLEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c07d1872-e2f9-47fa-d350-dae3b3f05175"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 3.8918e-02, -2.3701e-02],\n",
            "         [-8.6604e-02,  3.0205e-02],\n",
            "         [ 0.0000e+00,  0.0000e+00],\n",
            "         [-1.4104e-01,  5.3173e-02],\n",
            "         [-4.3205e-02,  2.4384e-02],\n",
            "         [-1.2025e-01,  4.1513e-02]],\n",
            "\n",
            "        [[ 3.8918e-02, -2.3701e-02],\n",
            "         [ 0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00],\n",
            "         [ 9.8875e-03, -6.0214e-03],\n",
            "         [ 1.2406e-04,  8.6702e-03],\n",
            "         [-2.5394e-02,  9.0371e-03]]], grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-head Attention\n",
        "run the attention mechanism multiple times (in parallel) with different, learned linear projections. This allows the model to jointly attend to information from different representation subspaces at different positions"
      ],
      "metadata": {
        "id": "-Iy9299HGYa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.cat([batch, causalatt(batch)], dim=-1)\n",
        "print(temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtZqDdOKrMBu",
        "outputId": "0283c90c-4c26-4b29-a0e2-fc51ccb9f89a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.4300,  0.1500,  0.8900,  0.0000,  0.0000],\n",
            "         [ 0.5500,  0.8700,  0.6600,  0.0000,  0.0000],\n",
            "         [ 0.5700,  0.8500,  0.6400, -0.1361,  0.0548],\n",
            "         [ 0.2200,  0.5800,  0.3300, -0.0387,  0.0138],\n",
            "         [ 0.7700,  0.2500,  0.1000, -0.0360,  0.0127],\n",
            "         [ 0.0500,  0.8000,  0.5500, -0.0930,  0.0350]],\n",
            "\n",
            "        [[ 0.4300,  0.1500,  0.8900,  0.0000,  0.0000],\n",
            "         [ 0.5500,  0.8700,  0.6600,  0.0197, -0.0120],\n",
            "         [ 0.5700,  0.8500,  0.6400, -0.1361,  0.0548],\n",
            "         [ 0.2200,  0.5800,  0.3300,  0.0099, -0.0060],\n",
            "         [ 0.7700,  0.2500,  0.1000, -0.0393,  0.0233],\n",
            "         [ 0.0500,  0.8000,  0.5500, -0.0254,  0.0090]]],\n",
            "       grad_fn=<CatBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, numheads, din, dout, contextlen, dropout, bias=False):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([\n",
        "      CausalAttention(din, dout, contextlen, dropout, bias) for _ in range(numheads)\n",
        "    ])\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "mulhattn = MultiHeadAttention(3, 3, 2, contextlen, 0.5)\n",
        "print(mulhattn(batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMJ5RFr7sZu6",
        "outputId": "16c146c7-45f9-4dcf-8640-1d28f11e9057"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0389, -0.0237,  0.0000,  0.0000, -1.1504, -0.3926],\n",
            "         [-0.1063,  0.0422,  0.4604, -0.5220, -0.5139,  0.0286],\n",
            "         [-0.1229,  0.0468,  0.3014, -0.3418, -0.6799,  0.0321],\n",
            "         [-0.0924,  0.0333,  1.0543, -1.2263, -0.3786,  0.0467],\n",
            "         [-0.0397,  0.0162,  0.6398, -0.8209, -0.4066,  0.0192],\n",
            "         [-0.0847,  0.0348,  0.5932, -0.6752,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.9813, -1.1128,  0.0000,  0.0000],\n",
            "         [-0.0866,  0.0302,  0.0000,  0.0000, -1.0882, -0.1674],\n",
            "         [ 0.0000,  0.0000,  1.4225, -1.6550, -0.7192, -0.1170],\n",
            "         [-0.0976,  0.0380,  0.6488, -0.7482, -0.3786,  0.0467],\n",
            "         [ 0.0000,  0.0000,  0.5389, -0.6143, -0.1016,  0.0296],\n",
            "         [ 0.0067, -0.0041,  0.9281, -1.0294, -0.3659, -0.0612]]],\n",
            "       grad_fn=<CatBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# (b, num_heads, num_tokens, head_dim) = (1, 2, 3, 4)\n",
        "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
        "                    [0.8993, 0.0390, 0.9268, 0.7388],\n",
        "                    [0.7179, 0.7058, 0.9156, 0.4340]],\n",
        "\n",
        "                   [[0.0772, 0.3565, 0.1479, 0.5331],\n",
        "                    [0.4066, 0.2318, 0.4545, 0.9737],\n",
        "                    [0.4606, 0.5159, 0.4220, 0.5786]]]])\n",
        "\n",
        "print(a @ a.transpose(2, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvVPhKutrYeb",
        "outputId": "34795412-43ca-4888-83e3-d86e6e53796c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[1.3208, 1.1631, 1.2879],\n",
            "          [1.1631, 2.2150, 1.8424],\n",
            "          [1.2879, 1.8424, 2.0402]],\n",
            "\n",
            "         [[0.4391, 0.7003, 0.5903],\n",
            "          [0.7003, 1.3737, 1.0620],\n",
            "          [0.5903, 1.0620, 0.9912]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.shape[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJL4PTEfzmUt",
        "outputId": "c406f84e-9f0d-4a1b-8547-dd6120b3c80d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a @ a.transpose(-2, -1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gRZrUeyrhh4",
        "outputId": "b6c76e8d-aa15-4694-8147-01d0b4fd3f9b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[1.3208, 1.1631, 1.2879],\n",
            "          [1.1631, 2.2150, 1.8424],\n",
            "          [1.2879, 1.8424, 2.0402]],\n",
            "\n",
            "         [[0.4391, 0.7003, 0.5903],\n",
            "          [0.7003, 1.3737, 1.0620],\n",
            "          [0.5903, 1.0620, 0.9912]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# more efficient way for multi-head attention\n",
        "import torch.nn as nn\n",
        "class MultiHeadAttentionV2(nn.Module):\n",
        "  def __init__(self, numhead, din, dout, contextlen, dropout, bias = False):\n",
        "    super().__init__()\n",
        "    self.dout=dout\n",
        "    assert(dout % numhead == 0)\n",
        "    self.headdim = dout // numhead\n",
        "    self.numhead = numhead\n",
        "\n",
        "    self.queryW = nn.Linear(din, dout, bias)\n",
        "    self.keyW = nn.Linear(din, dout, bias)\n",
        "    self.valueW = nn.Linear(din, dout, bias)\n",
        "    self.outproj = nn.Linear(dout, dout) # Linear layer to combine head outputs, can be removed in recent research\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer('mask', torch.triu(torch.ones(contextlen, contextlen), diagonal=1))\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, numstoken, din = x.shape\n",
        "\n",
        "    keys = self.keyW(x) #(b, numstoken, dout)\n",
        "    # print(\"keys before unroll:\", keys.shape, keys)\n",
        "    queries = self.queryW(x)\n",
        "    values = self.valueW(x)\n",
        "\n",
        "    keys = keys.view(b, numstoken, self.numhead, self.headdim) #(b, numstoken, numhead, headdim)\n",
        "    # print(\"keys after unroll:\", keys.shape, keys)\n",
        "    queries = queries.view(b, numstoken, self.numhead, self.headdim)\n",
        "    values = values.view(b, numstoken, self.numhead, self.headdim)\n",
        "\n",
        "    keys = keys.transpose(1, 2) #(b, numhead, numstoken, headdim)\n",
        "    queries = queries.transpose(1, 2)\n",
        "    values = values.transpose(1, 2)\n",
        "\n",
        "    attScores = queries @ keys.transpose(2,3) # 2,2,6,1 * 2,2,1,6=>2,2,6,6\n",
        "    # print(\"attScores\", attScores.shape, attScores)\n",
        "    attScores.masked_fill(self.mask.bool()[:numstoken, :numstoken], -torch.inf)\n",
        "\n",
        "    attWeights = torch.softmax(attScores / self.headdim**0.5, dim=-1)\n",
        "    # print(\"attWeights\", attWeights.shape, attWeights)\n",
        "    attWeights = self.dropout(attWeights)\n",
        "\n",
        "    contextVectors = attWeights @ values # 2,2,6,6 * 2,2,6,1=>2,2,6,1\n",
        "    contextVectors = contextVectors.transpose(1, 2) # (b, numstoken, numhead, headdim) 2,6,2,1\n",
        "    contextVectors = contextVectors.contiguous().view(b, numstoken, self.dout)\n",
        "    # contextVectors = contextVectors.reshape(b, numstoken, -1)\n",
        "    context_vec = self.outproj(contextVectors)\n",
        "    return context_vec\n",
        "\n"
      ],
      "metadata": {
        "id": "oJmHjQOKroWq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "batchSize, contextlen, din = batch.shape\n",
        "dout = 2\n",
        "mulhattn = MultiHeadAttentionV2(2,din,dout,contextlen, 0.5)\n",
        "contextVectors = mulhattn(batch)\n",
        "print(contextVectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOGxZqsN6Pjg",
        "outputId": "4ce8d0e2-43ec-413f-b8c3-357080628117"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.1541, -0.2885],\n",
            "         [-0.1894, -0.2814],\n",
            "         [-0.1704, -0.2907],\n",
            "         [-0.1093, -0.3168],\n",
            "         [-0.1915, -0.2895],\n",
            "         [-0.1205, -0.3202]],\n",
            "\n",
            "        [[-0.1306, -0.3122],\n",
            "         [-0.1862, -0.2963],\n",
            "         [-0.1976, -0.2744],\n",
            "         [-0.1286, -0.3099],\n",
            "         [-0.1991, -0.2713],\n",
            "         [-0.1703, -0.2929]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    }
  ]
}